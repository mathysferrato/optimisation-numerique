{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> TP-Projet d'optimisation numérique </h1>\n",
    "<h1> Algorithme de Newton </h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation \n",
    " \n",
    "1. Coder l’algorithme de Newton local en respectant la spécification ci-dessous (fichier `Algorithme_De_Newton.jl`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithme_De_Newton"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using Pkg\n",
    "#Pkg.add(\"Documenter\")\n",
    "using LinearAlgebra\n",
    "using Documenter\n",
    "using Markdown  \n",
    "include(\"Algorithme_De_Newton.jl\")\n",
    "#@doc Algorithme_De_Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vérifier que les tests ci-dessous passent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1m Time\u001b[22m\n",
      "Test algo newton | \u001b[32m  22  \u001b[39m\u001b[36m   22  \u001b[39m\u001b[0m11.0s\n"
     ]
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "# Tolérance pour les tests d'égalité\n",
    "tol_erreur = sqrt(eps())\n",
    "\n",
    "## ajouter les fonctions de test\n",
    "include(\"../test/fonctions_de_tests.jl\")\n",
    "include(\"../test/tester_algo_newton.jl\")\n",
    "include(\"../src/Algorithme_De_Newton.jl\")\n",
    "\n",
    "affiche = false # Mettre affiche = true pour afficher les résultats \n",
    "\t\t\t\t# des appels à l'algorithme de Newton. Cela peut vous\n",
    "\t\t\t\t# servir pour les réponses aux questions en fin de notebook.\n",
    "\n",
    "@testset \"Test algo newton\" begin\n",
    "\t# Tester l'algorithme de Newton\n",
    "\ttester_algo_newton(affiche,Algorithme_De_Newton)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial -1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5707963267948966\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial -1.0707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = -1.5707963267949088\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 3\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial 1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = 1.5707963267948966\n",
      "  * f(xsol) = 1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n"
     ]
    }
   ],
   "source": [
    "#using Pkg; Pkg.add(\"LinearAlgebra\"); Pkg.add(\"Markdown\")\n",
    "# using Documenter\n",
    "using LinearAlgebra\n",
    "using Markdown                             # Pour que les docstrings en début des fonctions ne posent\n",
    "                                           # pas de soucis. Ces docstrings sont utiles pour générer \n",
    "                                           # la documentation sous GitHub\n",
    "include(\"Algorithme_De_Newton.jl\")\n",
    "\n",
    "# Affichage les sorties de l'algorithme des Régions de confiance\n",
    "function my_afficher_resultats(algo,nom_fct,point_init,xmin,fxmin,flag,sol_exacte,nbiters)\n",
    "\tprintln(\"-------------------------------------------------------------------------\")\n",
    "\tprintstyled(\"Résultats de : \",algo, \" appliqué à \",nom_fct, \" au point initial \", point_init, \":\\n\",bold=true,color=:blue)\n",
    "\tprintln(\"  * xsol = \",xmin)\n",
    "\tprintln(\"  * f(xsol) = \",fxmin)\n",
    "\tprintln(\"  * nb_iters = \",nbiters)\n",
    "\tprintln(\"  * flag = \",flag)\n",
    "\tprintln(\"  * sol_exacte : \", sol_exacte)\n",
    "end\n",
    "\n",
    "# Fonction f0\n",
    "# -----------\n",
    "f0(x) =  sin(x)\n",
    "# la gradient de la fonction f0\n",
    "grad_f0(x) = cos(x)\n",
    "# la hessienne de la fonction f0\n",
    "hess_f0(x) = -sin(x)\n",
    "sol_exacte = -pi/2\n",
    "options = []\n",
    "\n",
    "x0 = sol_exacte\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = -pi/2+0.5\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = pi/2\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation \n",
    "\n",
    "1. Justifier les résultats obtenus pour l'exemple $f_0$ ci-dessus;\n",
    "\n",
    "2. Soit \n",
    "$$ f_{1} : \\mathbb{R}^3 \\rightarrow \\mathbb{R} (x_1,x_2, x_3) \\mapsto  2 (x_1 +x_2 + x_3 -3)^2 + (x_1-x_2)^2 + (x_2 - x_3)^2$$ \n",
    "\n",
    "Justifier que l’algorithme implémenté converge en une itération pour $f_{1}$;\n",
    "\n",
    "3. Soit \n",
    "$$ f_{2} : \\mathbb{R}^2 \\rightarrow \\mathbb{R} (x_1,x_2) \\mapsto 100(x_2-x_1^2)^2 + (1-x_1)^2 $$ \n",
    "\n",
    "Justifier que l’algorithme puisse ne pas converger pour $f_{2}$ avec certains points initiaux.\n",
    "\n",
    "**Remarque.** Vous pouvez mettre `affiche=true` dans les tests de l'algorithme de Newton pour\n",
    "vous aider.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réponses\n",
    "\n",
    "1. - Pour le 1er point initial, on a $ x_0 = sol_{exacte} $ donc aucune itération n'est effectuée puisque la CN1 est déjà verifiée, on a donc $ nb_{iters} = 0 $ et la raison d'arrêt n'est pas modifiée ($ flag = 0 $).\n",
    "   - Pour le 2e point initial, en rajoutant en début de boucle, un println dans le code de `Algorithme_De_Newton.jl`, on a accès aux valeurs du gradient aux différentes étapes, soit :\n",
    "      - $\\lVert \\nabla f_0(x_0) \\rVert = 0.47942553860420306$\n",
    "      - $\\lVert \\nabla f_0(x_1) \\rVert= 0.04628594680720124$\n",
    "      - $\\lVert \\nabla f_0(x_2) \\rVert = 3.311802132022446.10^{-5}$\n",
    "      - $\\lVert \\nabla f_0(x_3) \\rVert = 1.2151220930919354.10^{-14}$\n",
    "\n",
    "      Comme options = [], on a $Tol_{abs} = 1.4901161193847656.10^{-8}$ et $\\;Tol_{rel} = 10^{-15}$\n",
    "\n",
    "      Ainsi, $\\max (\\lVert \\nabla f_0(x_0) \\rVert \\times Tol_{rel}, Tol_{abs}) = Tol_{abs} << \\lVert \\nabla f_0(x_2) \\rVert$\n",
    "\n",
    "      Et $Tol_{abs} >> \\lVert \\nabla f_0(x_3) \\rVert$ d'où la convergence en 3 itérations.\n",
    "\n",
    "   - Pour le dernier cas, on a $x_0 = \\cfrac{\\pi}{2} \\;$ or $\\nabla f_0(x) = \\cos(x)$ donc $\\nabla f_0(x_0) = 0$ et on converge sans itération.\n",
    "\n",
    "2. Pour répondre à cette question on considère tout $x_0 \\neq [1; 1; 1]$ car sinon l'algorithme converge sans itération puisque $[1;1;1]$ annule le gradient.\n",
    "\n",
    "   On a $x_1 = x_0 + d_0$ et $\\nabla^2 f_1(x_0)d_0 = -\\nabla f_1(x_0)$. En résolvant ce système, on obtient $d_0 = -x_0 + [1;1;1]$\n",
    "\n",
    "   Ainsi, $x_1 = [1;1;1]$ donc $\\nabla f_1(x_1) = 0_{\\mathbf{R^3}}$ donc l'algorithme converge en une itération.\n",
    "\n",
    "3. Si $\\nabla^2 f_2(x)$ n'est pas inversible alors l'algorithme ne pourra pas converger.\n",
    "   On trouve que $\\det(\\nabla^2 f_2(x)) = 0 \\Leftrightarrow x_2 = \\cfrac{1}{200} + x_1^2 $\n",
    "\n",
    "   Donc $\\forall x_0 \\; tq \\; x_{0,2} = \\cfrac{1}{200} + x_{0,1}^2\\;$, l'algorithme ne convergera pas.\n",
    "\n",
    "   Par exemple, on remarque que dans les tests, lorsque $x_0 = [0; \\cfrac{1}{200} + \\cfrac{1}{10^{12}}]\\;$, on sort de l'algorithme avec flag = 3 donc il n'a pas convergé."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
